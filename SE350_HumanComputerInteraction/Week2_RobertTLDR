Week2_RobertTLDR

Lectures:
	1	Usability Evaluation
	2	Heuristic Evaluation
	3	Usability Testing 1

Lecture 1: Usability Evaluation
	Learning Objectives:
		- Define usability
		- Describe aspects & Mesures of context
		- Compare/Contrast usability evaluation techniques
		- Use correct evaluation technique for problem

	1.1: Usability
		- Measures quality of user experience when using product
		- Quality attribute, assess how easy interface is to use

		-Ensure user can use system as it was intended to be used
		- Many examples of bad usability, can be solved easily


	1.2: Fit for use: 
		- Can system support tasks user wants to do?
		- Usability testing != System testing
		- Can create metric to measure error frequency (Such as 2 errors per hour)

	1.3: Ease of Learning: 
		- How fast can new user learn to do basic task on system
		- Are you expected to read a manual?
		- How much time do you invest learning interface?

	1.4: Efficiency of use: 
		- How fast can experienced user finish task?
		- Would it be quicker to order pizza on phone or do it online?

	1.5: Memorability: 
		- Can user remember where things are, if they've used the system before.
		- Interface good if you can recall how to do someting
		- If you expect a user to do something often then expect them to have remembered how to do it
		- Make a feature that you don't expect to be used as simple as possible

	1.6: Error Frequency & Severity: 
		- How often/serious are errors that users encounter when user uses system.
		- Think of the cost of a specific error happening
		- Try changing input type to prevent various incorrect options

		Slip = Understand goal but incorrect action
		Mistake = May not even have correct goal, as well as incorrect action

	1.7: Subjective Satisfaction: 
		- Does user like using system?
		- If do then probably will make less errors
		- Aesthetics very important. Ugly may be tiring for the user.

	1.8: Performance Measurements
		Analytical = directly from interface
		Empirical = Observed from usability study

		1.8.1: Fitt's Law:
			The larger the distance or the smaller the targer, the longer it takes for user to do task. LOG RELATIONSHIP

		1.8.2: Hick-Hyman Law:
			Time taken to make decision for N choices increases by LOG FACTOR

Lecture 2: Heuristic Evaluation
	Learning Objectives:
	- Be aware of heuristic evaluation options
		Nielsen's Heuristics
	- Undesrstand evaluation challenges of early prototypes with limited functionality


	2.1: Heuristic Evaluation
		- Performed by experts using criteria to measure usability of a design
		- Evaluator goes through scenario and tests each step on the way
		- Lets you understand a system before a usability test
		- Can be done standalone: make observation/give recommendations

		Nielsen's Heuristics:
		1: Visiblity of System Status
			- Keep user informed of what's going on

		2: Match between System and Real World
			- Matching vocabulary with user expecataton/knowledge
			- Does workflow match task being performed
			- Correct affordance

		3: User Control and Freedom
			- Ensure common control features (EXIT, UNDO, REDO) clearly marked

		4: Consistency and Standards
			- Follow platform conventions 
			- have consistent terminology used?

		5: Error Prevention
			- Remove error prone conditions
			- Make error checking present, and user prompted?

		6: Recognition Rather than Recall
			- Minimise brain memory load
			- make things that they want to do visible

		7: Flexibility and Efficiency of Use
			- Add accelerators for those that are familiar with the system

		8: Aesthetic and Minimilst Design
			- Remove irrelevant or uncessary information

		9: Help user Recognise/Diagnose/Recover from Error
			- Make error messages easy to read and understand so user can try find a solution

		10: Help & Documentation
			- Easy to read/search and focussed on the task at hand

	2.2: Advice for evaluations
		- Not always a concrete and objective way to do something. May need to do some further testing and validation of even the evaluators.
		- many heuristics exist of different types. Each to serve their own purpose.

	2.3: Evaluating prototypes.
		- Evaluation of early protype differnt to that of finished system
		- due to lack of features/functionality.

		2.3.1: Wizard of Oz evaluation
			- Using a human to emulate the functionality of a system whilst having 0 actual functionality
			- used to see reactions to using your system. 
			- The less realistic the prototype the more creative the responses will be.

	2.4: Functional Prototypes
		Interactive prototypes that represent some functionality of the end system, but not all of it.

		Can be created using prototyping tool BALSAMIQ, or fully fledged programming languages/IDEs

		Prototyping tools:
			Advantages: Closer to real interface and can better represent functionality

			Disadvantages: Lock down design to something concrete, limits creativity
