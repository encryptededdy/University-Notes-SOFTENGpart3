\documentclass{article} 
\newcommand\tab[1][0.5cm]{\hspace*{#1}}

\title{SOFTENG 370 Notes}
\author{Theodore Oswandi} 

\usepackage[
	lmargin=2.5cm,
	rmargin=5cm,
	tmargin=1cm,
	bmargin=3cm,
	]{geometry}
\usepackage{enumitem}
\setlist{noitemsep}
\usepackage[none]{hyphenat}

\begin{document} 
\maketitle{} 

\tableofcontents
\newpage

\section{Lecture 1}
	\subsection{Generics}
		\paragraph{\tab Operating System} The software that makes the computer usable. Using modern computers without an OS is "impossible"
			\\ \tab \textbf{Examples: }Windows, OSX, Linux, Unix, iOS, Android, etc...

		% \paragraph{\tab Things that are part of an OS?}
		% \begin{enumerate}
		% 	\item File System
		% 	\item Communication System
		% 	\item Process Manager
		% 	\item Security Manager
		% 	\item Memory Manager
		% 	\item Graphical User Interface
		% 	\item Backup System
		% 	\item Web Browser
		% 	\item Media Player
		% 	\item Compiler
		% 	\item Java/.Net environment.
		% \end{enumerate}

	\subsection{Approaches to Understanding}
		\paragraph{\tab Minimalist}
		\begin{itemize}
			\item mostly going to be using this one
			\item OS contains minimum amount of software to function
			\item archlike
		\end{itemize}

		\paragraph{\tab Maximalist}
		\begin{itemize}
			\item All software comes with standard OS release.
			\item Contains many utilities and programs.
			\item ubuntuish
		\end{itemize}

	\subsection{Usable vs Efficient}
		\begin{itemize}
			\item make sure you make OS suited for needs
			\item either specialised or more general purpose
			\item Think of who you expect to use the system
			\item If creating a realtime system with potentially thousands of operations in a short amount of time, have to consider efficiency
			\item Same with battery life if you expect the system to be used in a mobile setting.
		\end{itemize}

	\subsection{OS themes}
		\paragraph{\tab Manager Model}
			\begin{itemize}
				\item OS is colleciton of managers, ensuring proper use of devices.
				\item Managers are independent.
				\item look out for everything associated with computer 
				\item tie in with hardware. Current state of HW lets OS do more/less things
			\end{itemize}


		\paragraph{\tab Onion Model}
			\begin{itemize}
				\item Onions have layers (Abstractions)
				\item resources contained in lower layers. 
				\item Lower layers can't access higher level layers but other way around possible
				\item Very difficult to get these layers 'right'
				\item can use in terms of security. Very good idea
			\end{itemize}

		\paragraph{\tab Resource Allocator Model}
			\begin{itemize}
				\item similar to manager model
				\item emphasis on fairness and providing services
			\end{itemize}

		\paragraph{\tab Dustbin Model}
			\begin{itemize}
				\item contains middleware that not considered part of OS
				\item Sees OS as bits no-one wants to do
			\end{itemize}

		\paragraph{\tab Getting Work Done Model}
			\begin{itemize}
				\item Idea of it is we use computers to do something else.
				\item Goal for OS is to help be able to get it all done.
			\end{itemize}

	% Things we should know
	% 	Interrupt
	% 	Security&Protection
	% 	FileSystem
	% 	VirtualMemory
	% 	Processes&Threads

	\subsection{OS design}
		\subsubsection{Themes}
			\paragraph{\tab All in one}
			\begin{itemize}
				\item All OS components freely interact with each other
				\item MS-DOR and Early Linux
			\end{itemize}

			\paragraph{\tab Separate Layers (Onion Model)}
			\begin{itemize}
				\item Simplify verificiation and debugging
				\item Correct design difficult to get
			\end{itemize}

			\paragraph{\tab Modules}
			\begin{itemize}
				\item All in one with modules for some features
				\item Linux and Windows.
			\end{itemize}

			\paragraph{\tab Microkernels}
			\begin{itemize}
				\item Client/Server model
				\item make OS as small as possible

				\item \textbf{Exokernel} puts kernel outside. OS's job only need to authenticate people to use hardware.
			\end{itemize}

			\paragraph{\tab VMs}
			\begin{itemize}
				\item Java is an example of this
			\end{itemize}

	\subsubsection{MS-DOS}
		\begin{itemize}
			\item Written to provide the most functionality in the least amount of space
			\item not divided into modules
			\item Something exokernels trying to do. Make application program access hardware directly.
		\end{itemize}

	\subsubsection{Early Unix}
		\begin{itemize}
			\item UNIX OS in 2 parts. \textbf{Kernel} and \textbf{System Programs}
			\item Provides:
				\begin{itemize}
					\item File System
					\item CPU sheduling
					\item Memory management
					\item Other OS functions
				\end{itemize}
			\item Ken Thompson and Dennis Ritchie
			\item Make OS as simple as possible.
			\item Simple 2 letter commands.
			\item Ideas of pipelining and process communication
		\end{itemize}

	\subsubsection{THE Multiprogramming System}
		\begin{itemize}
			\item THE was the first to use the layered system
			\item Contains 6 layers:
				\begin{enumerate}
					\item[5] User programs
					\item[4] Input/Output buffering
					\item[3] Operator-Console device driver
					\item[2] Memory Management
					\item[1] CPU scheduling
					\item[0] Hardware
				\end{enumerate}
		\end{itemize}

	\subsubsection{WinNT and Client/Server}
		\begin{itemize}
			\item WinNT still being still run
				\begin{itemize}
					\item Win10 now has Windows Subsystem for Linux
				\end{itemize}
			\item NT provide env subsystem to run code written for differnt OS
			\item NT and successors are hybrid systems. Parts are layered but some merged to improve performance.
		\end{itemize}
		

\section{Lecture 2: History of OS}
	\begin{itemize}
		\item Started at mainframes.
		\begin{itemize}
			\item Early PDAs were similar to mainframes. Had no memory protection.
		\end{itemize}
		\item Then go to Minicomputers
		\item And then desktop
		\item And how handheld computers
	\end{itemize}

	\paragraph{\tab Each of these stages go through cycle of:}
	\begin{enumerate}
		\item No software
		\item Compulers
		\item Multiuser
		\item Networked
		\item Clustered
		\item Distributed Systems
		\item Multiprocessor \& Fault tolerant.
	\end{enumerate}

	\subsection{Total Control}
		\begin{itemize}
			\item Computers expensive in 50s. Data and programs were saved on paper tape.
			\item Programmers knew how the computer worked. They were very knowledgable about computers.
			\begin{itemize}
				\item Prepared program and data cards
				\item do setup
				\item control computer
				\item debug
			\end{itemize}
			\item Computers did 10,000s instructions per second, but were idle a lot of the time.
		\end{itemize}

	\subsection{Properties of old OS}
		\begin{itemize}
			\item \textbf{IO polling}, since no other programs running in background, therefore just waiting on input and able to just poll.
			\item No file system
			\item No memory management or security
			\item OS defined by decisions made by user.
			\item Single program at a time
		\end{itemize}

	\subsection{Progression: Operators \& Offlining}
		\paragraph{\tab Operators}
		\begin{itemize}
			\item Goal is to reduce the time CPU was doing nothing.
			\item Operators now just "use" the computer. No need for programmer.
			\begin{itemize}
				\item If something crashes, then just start the next program.
				\item Batch similar jobs together, maximise usage of computer.
			\end{itemize}
		\end{itemize}

		\paragraph{\tab Offlining}
		\begin{itemize}
			\item Form of parallelism in early computing.
			\item With Big Expensive Computer BEC, but they are just waiting for IO a lot of time. Therefore want to make IO as fast as possible.
			\item Use smaller computers to convert slower paper to faster magnetic tape. Then that magnetic tape is used as IO for the BEC
			\item This is the same for output. Have another smaller cheaper computer offload the output magnetic tape from BEC to a printer.
		\end{itemize}

		\paragraph{\tab Resident Monitor}
		\begin{itemize}
			\item Keep some code in memory.
			\item It did the work that some operators were doing.
			\begin{itemize}
				\item clearing memory
				\item reading start of new program that needs to be loaded.
				\item Can also do some of the IO routines.
			\end{itemize}
		\end{itemize}

		\paragraph{\tab Control Programs}
		Standardise the language to communicate with the Resident Monitor.
		\\ Had tags for things such as \$JOB (for signifying jobs), \$FTN (When fortran compiler needed), and \$END (signifying end of program)

		\paragraph{Conclusions from this}
		\begin{itemize}
			\item Memory management and file system still not present. Therefore still need to reset if anything bad happens.
			\item Security patchy at best
			\item Still need IO polling
			\item Standard IO routines for programmers
			\item 2 programs in memory, but one executed
			\item User interface was JCL (Job Control Language)
			\item Output of program can be input of another.
		\end{itemize}

	\subsection{Changes in Hardware}
		\begin{itemize}
			\item\textbf{Disk drives} provide faster IO.
			\item Processors that you can \textbf{interrupt} also means that there is no more reliance on polling.
			\item IO devices and CPU concurrent execution, and use local buffer.
		\end{itemize}

		\paragraph{\tab SPOOLING (Simultaneous Peripheral Operation On-Line)}
			Meaning that when interrupt, contents of cards read to disk.
			Therefore current program interrupted.

	\subsection{Multiprogramming}
		\begin{itemize}
			\item Putting multiple programs on at once. Need more memory to do this.
			\item Now also need for scheduler to manage multiple users' program needs.
			\begin{itemize}
				\item Need to figure out how to manage stuff. Priority of jobs, how much time to allocate for these jobs, etc...
			\end{itemize}
			\item No memory protection, so programs could overwrite other program's chunk of memory.
			\begin{itemize}
				\item Java is an example of somehting that doesn't give you direct access to memory in JVM.
				\item Memory Protection better done by hardware than having software impose limits. 
			\end{itemize}
			\item \textbf{Requirements} Limited address range and Operating modes.
		\end{itemize}

		\paragraph{\tab Memory Protection Modes}
		\begin{enumerate}
			\item User/Restricted Mode
			\begin{itemize}
				\item Execution is done on behalf of the user.
				\item User should not have access to privileged instructions
			\end{itemize}
			\item Kernel Mode (SU)
			\begin{itemize}
				\item Execution done on behalf of the operating system
				\item Full access to all instructions.
			\end{itemize}
		\end{enumerate}
		A \textbf{mode bit} can be used to signify what mode a certain program is running in. If something in user mode tries to access memory it is not allocated to, it will go to Kernel mode and throw exception before going back to User mode.

		\paragraph{Why we need both} We need both because:
		\\\tab If modes existed with relevent instructions, but full memory access; there will still be a lack of memory protection, but also no privilege instruction protection. You can put whatever code you want anywhere.
		\\\tab If memory access limited but no modes or privilege access; then the user will be able to modify amount of memory available for programs.

		\paragraph{\tab Memory Protection}
		\begin{itemize}
			\item Process gets fixed area of memory that it can use
			\item If tries to access address out of that range then exception will be thrown.
			\item Base and Limit register set for each process and how much memory it can have. 
		\end{itemize}

	\subsection{Batch Systems}
		\paragraph{}Memory protection and Processor modes allow you to safely put multiple programs in memory.

		\paragraph{\tab Features}
		\begin{itemize}
			\item Jobs have their own protected memory
			\item Disks have file systems. Files linked to owners
			\item Automated Scheduling. Utilise hardware as much as possible, as operators are slow. Also allows fine tuning of how scheduler works.
			\item Computer consoles
		\end{itemize}

		Not much has changed from programmer's point of view.


\section{Lecture 3: History Continued}
	\subsection{Scheduling}
		\begin{itemize}
			\item Ams to maximise use of computing machinery OS knows
			\item Need to know details about device and file processes. What how much resources to allocate.
			\item Also has to take into account timing and output size.
		\end{itemize}

		SOMETHING ABOUT UNIVERSITY OF AUCKLAND SYSTEM

	\subsection{Power to the people}
		\begin{itemize}
			\item Due to hardware becoming cheaper, can have general public own personal computers
			\item Used to use teletypewriters, but used CRT TVs after a certain point. Editing text was difficult.
			\item At early 1970s, can code in similar style then you do now.
		\end{itemize}

	\subsection{Time Sharing System}
		\begin{itemize}
			\item People don't like waiting.
			\begin{itemize}
				\item 200ms+ noticable
				\item 5000ms+ unacceptible
			\end{itemize}
			\item Difficult for scheduler to figure out how to allocate resources. People use different computer differently with differing IO demands.
			\item Users expect command to run as soon as you press Enter.
			\item Don't want to have everything run at 100\%, otherwise it feels too slow.
			\item Security an issue for all of these people writing on terminal. Have to increase this and have authentication.
		\end{itemize}
		
		\paragraph{\tab Remnants of Batch Programming}
		\begin{itemize}
			\item Has way to run process at given time
			\item Terminal looked like cards until better graphics came
		\end{itemize}

	\subsection{1980s computers}
		\begin{itemize}
			\item Cycle starts again, started with Resident Monitor Systems.
			\item Simple single layer file systems
			\item No security, everything stored on disks. Didn't bother as it was aimed at individual users.
			\item Did spooling later, for printer output.
			\item Putting more than one program in memory, using similar system to resident monitor.
			\item Higher definition screens, pixel addressing for graphics.
			\item Cycle continues, things like time-sharing features and implementation of UNIX.
		\end{itemize}

		Xerox created GUI elements for Office use. Then Apple engineers used ideas to create their Mac.

		\paragraph{\tab Features}
		\begin{enumerate}
			\item Virtual memory
			\item Multiprogramming
			\item Complex file system
			\item Networking
			\item Multi-user
		\end{enumerate}

	\subsection{1980s Networking}
		\textbf{Security}, Transparency and Protocols/Standardisation create new problems.\\
		\textbf{Network OS:} File sharing, communication scheme, running independent to other machines on network.\\
		\textbf{Distributed OS:} Sharing processing power and resources of lots of computers to make it look like only single system.

	\subsection{Multiprocessor Systems}
		Heat is an issue, kind of a soft cap on processor frequency.
		Therefore can add more cores instead of trying to make each core faster.

		\paragraph{Tightly Coupled System} Processors sharing memory and clock. Communication through this shared memory. Most computers are now this.

		\paragraph{Parallel Systems} Mean increased throughput and cheaper way to increase performance. WIth increased reliability and rate of degradation.

		\paragraph{Symmetric Multiprocessing: }All core running same OS, most modern systems run this way
		
		\paragraph{Asymmetric Multiprocess}	Different cores allocated to different jobs/section. Used in very large systems.


	\subsection{Realtime System}
		Timing constraints very important.
		\paragraph{\tab Hard real-time}
		\begin{itemize}
			\item must run within time, or failure happens
			\item Has to be specifically designed to be hard realtime
			\item Nuclear plants, air traffic control
		\end{itemize}

		\paragraph{\tab Soft real-time}
		\begin{itemize}
			\item Doesn't matter too much, more lax.
			\item Most OS handle soft realtime
			\item Phone system, multimedia
		\end{itemize}

	\subsection{Pocket Computer \& Smartphones}
		\begin{itemize}
			\item Started as PDA/Pocket computers.
			\item Went through cycle again. Started as resident monitors.
			\begin{itemize}
				\item Due to hardware limitations, so have to start at the basic level again.
			\end{itemize}
			\item Battery life and power consumption very important factors.
		\end{itemize}

		\paragraph{PalmOS} Operating system that PalmPDAs ran on. \\
		Small memory with slow processor. \\
		Efficiency very important factor, to just get passable performance.

		\paragraph{Android} Popular operating system for current smartphones.\\
		Linux based, application programming in Java. \\
		Google trying to build their own kernel to replace Linux (Fuchsia)

		\paragraph{iOS} Operating systems that mobile Apple products run on. \\
		Based on OSX (Their desktop OS)\\
		virtual memory and paging for code but not data as writing to flash degrades it.



\section{Assignment Notes}
	\begin{itemize}
		\item Use standard UNIX symbols to control the threads

		\item setupstacktransfer()
		\begin{itemize} 
			\item \textbf{siguser1}	represents the user's signal. Let you send stuff to yourself
			\\ \tab similar to interrupt, but done in software and not hardware

			\item \textbf{sigaction} is a struct that holds information. Kind of like an object
			\\ \tab is global due to process having to be able to get to it at any time

			\item Has a separate, special stack for that singal handler to use.
			\item \textbf{man pages} are really important for this assignment. 
			\item If want to get all man pages relevant to signal then use $man -k signal$
		\end{itemize}

		\item Threads need their own stack
			\\ \tab Running independedntly of each other and calling their own functions so to guarantee proper functionng it is best for them to have their own stack

		\item \textbf{\&setupaction}
			address of instructions for the signal handler

		\item \textbf{thread1()}
		contains code that will be executed in the thread

		\item threadfuncts is array of names of functions that should be called for all threads
		If add more then you need to add to the array

		\item In task 2; 3 threads but 2 of them running the same logic from thread2()

		\item Information about thread structure found in littleThread.h

		\item static variables aren't allocated on the stack. And preserve value throughout multiple function calls

		\item MISSED UP TO LIKE 35min in

		\item \textbf{sigaltstack} lets you use that special alternate stack for different threads
		\\ \tab have malloc some memory and will use it
		\\ \tab When you call associateStack() when making new process you make a new alternate stack

		\item \textbf{kill(getpid(), SIGUSR1);}
		\\ \tab KILL is system call to get signals. Set it up but haven't associated it with anything it yet
		\\ \tab KILL sending pid of process you want to send it to. Send signal to yourself (try to kill yourself).
		% \\ \tab 

		\item make local copy of thread in fuction and set it to READY.

		\item C doesn't have exception handling. Therefore if error happens in a stack then need the ability to jump to part of memory to give error.
		\begin{itemize}
			\item \textbf{setjmp}: Take snapshot of where you are. Registers of processor (PC will contain this). Can also be used to "freeze" state of a given thread if need to be suspended.
			\item \textbf{longjmp}: Jump back to state where setjmp called. Can be used to "unfreeze" an already suspended thread to resume it. [Line34 in OSA.c]
			\item Copy stack information/register information and when jump back then recopy it back to "jump back to where you were"
			\item variable states preserved if stored on the stack
			\item if setjmp return 0 then returned directly, or nonzero if from longjmp. Will be used later for forking to create new processes, to check if from parent or child
		\end{itemize}

		\item \textbf{Switches} Pass it your current thread and the thread you want to go to.

		\item Only one thread running at a time, other ones will be READY due to only using a single processor.



		\item can get this assignment to work without understanding it
	\end{itemize}


\section{Lecture 4: Virtual Machines}
	./ used to signify that it isn't an internal command

	MISSED TO VIRTUALISATION

	Virtualisation
		if running on hardware then want to be as close to 90\% performance as possible. Preferably 95-98 but not always possible

	Design of IBM vm
		make each user feel like they have own cpu
		minidisk = lets user feel like they have access to whole drive
		problem is you don't want actual kernel mode to be accessable to all guests
			solution is each user has their own virtual kernel mode, but this kernel mode actually runs on the user level.
			Priviledged instructions actually needed to be passed down as not all things kernel does need that mode

	Hypervisor Types
		Allocating resources to VM 
			- like actual CPU cores
			- or chunks of memory allocated for it
		Can have "nested" vms

		Type 1
			Special purpose OS
			have support for bunch of tools to make using it easier

		Type 2
			Ones that you install yourself. (virtualbox, parallels)
			Run applications on host

	Problems
		trap and emulate couldn't be run on x86 up to a point.


	Hardware virtualisation x86
		Most OS only use level 0 (kernel mode) and level 3 (user mode)
		Problem with VM in real machine, then you need to keep track about process and registers. Have to keep track of this for all processes.
			Hardware system lets you change processor for one VM to another

		each VM page tables for their own processors
			used to have nested page table system. VMs create their own virtual page tables and some will exist in real memory

	Solutions
		Binary translation
			Look at instructions before execution, problem instructions get translated to be safer to be run in kernel mode

			These translations are similar
			Only translated code is run

	OS level virutalisation
		If lots of machines running same OS, then can use containers that make it seem like they are all separate. 
		Useful for servers
		Simpler than VMs as they are sharing same copy of OS

	More Styles
		paravirtualisation - XEN
			modify source code of OS you want to run
			increase efficiency to allow calls to be made straight to VMM instead of process

		Application Virtualisation
			WINE
			Want to run something made for an OS on another OS
			Makes the application think like its running on intended OS

		Windows Subsystem for Linux
			Not really virtual machines
			If app makes linux kernel call, kernel figures it out and sends it to subsystem
			Tied into kernel level, applicaiton doesn't really know about it. It just functions as normal and kernel does all of the work.

	C and OS implementations

Week 2 friday
	MISSED 10 MINUTES OF LECTURE

	Direct access to memory: address.c
		Whenever you run the program, the stack address space is different
		This is for security
			ASLR address space layout randomisation.
				Stack, heap and libraries put in different addresses.
				Helps add level of security

	Accessing Registers
		Can choose to store something in a register
		Use keyword 'register' prefacing variable type on initalise
		Can't get address of register, so if set to register OS may put it out of register into memory if you try get address of variable

	Volatile
		Another keyword prefacing variable type
		Don't do any clever tricks
			When you don't know if variable value will have changed due to non-local reason due to things like interrupt.

		Whenever you use this variable, you have to go back to memory and check its value again as it may have changed.

	Memory Management
		No memory management
		Static memory allocated at runtime, no malloc. But hard to get rid of them

	Dynamic memory
		Garbage collection doesn't inherently exist. As it is unpredictable

		Allocating stack space can be done by calling 'free'
		Free knows how much memory to free up since malloc uses a little bit more space just above for length of bit of stuff stored

	Inline assembly
		Example code is 32bit OS dependant
		Can put assembly language directly in C code

	Running commands from C program
		system() lets you put string of command you want to use

	Alternatives (languages for OS)
		C++
			similar to C but with object stuff too
			Windows has C kernel with some C++ and C\#
		Objective C
			MacOS written with ObjC, but trying to move to Swift
		Java
			Can't exclusively use java, need stuff with other stuff as well
		Assembly
			old school if you need even more fine tuning

More assignment stuff
	Part 1
		create a lot of threads, link them together (linked list)
		circular linked list (doubly) 
		keep going around cycle of threads until all finished executing.
		Only 2 threads given, but should be able to do with n threads
	Part 2
		Add thread.yield()
		This will call transition system like in part 1.
		Stop current thread (not finished) and pausing itself to allow another thread to run.
	Part 3
		Interrupt the thread with external source
		use set.itimer, send signal to processor to signify event happening. (timer has run out, every 20ms)
		Tells current thread to pause externally and start next thread.

Processes
	Instance of program execution
	Thing OS uses as construct to control work

Two parts
	Resources/Task/Job
		files open and using
		windows on screen
		restrictions on process
	Code that's running
		what process is actually doing
		these days have threads for multiple streams of instructions

Thread
	sequence of instructions executing without interruption
		this does happen, but not from thread's point of view. Thread can't tell if it has been paused or not
	Can run multiple threads but share resources

Typical uses
	split work accroess processors/cores
		thread for user response, another for some computation task
		GUI threads and process threads
	Server applications, have threads for clients.
		Server preallocates set of threads for handling requests

Thread implementations
	user level	
		OS sees one thread per process

		advantages
			work if os doesn't support threads
			easier to make, no system calls
			application specific control
			switching is easier (some have register files for threads)

	System level
		operating system knows about it
		controlled by system calls
		System knows about state of thread as well. Therefore will schedule based on their state

		advantages
			Threads treated separately
			If multiprocessor, then can schedule different threads on differnt processors
			thread blocking in kernel doesn't stop all thread on same process
				for example if doing read on file, usually code will wait for result and therefore block
				can allocate cpu to do something in the meantime in this case

	Jacketing
		Check "will I block" before doing something that may block
			check to see if data already exist in memory. If already there cna just get it without having to block. if have to get it, then let processor do something else while it tries to get data

	Best of Both worlds
		Solaris had both system and user level threads before ver9
			Uses one to one mapping of user level to kernel level threads.
			Mapping of single lightweight process to kernel threads. 
				lightweight processes
			If something on user level thread makes blocking call, other threads on that lightweight process gets to do its thing
				system makes its own kernel thread and new lightweight process to allow this to happen
		Windows 7 threads
			Since Win7 then have user mode scheduling. This also tries to get the best of both world
		Linux threads
			Used to not have threads, everything put on one thread
			Clone call
				makes a new process. Shares memory, open files and signal handlers
			Saw them as processes and not threads, so scheduled them
			Can't signal whole thread, therefore since cloned you aren't sending it to all of them and only the one you specify
			Killing threads dangerous, due to them sharing memory, then if killed then blocking may cause memory to be in inconsistent state as lock has not been released yet
			In POSIX, don't actually kill threads. You tell it to cancel itself instead, telling it to die at some point
				Threads are written in such as way that before it makes a blocking system call, it does some tidying so cancellations can happen
			Cloned threads can't block if other clone made blocking system call






Week 3 Wednesday
	More on threads and processes
	Part 3 assignment
		numthreads constant will be correct
			can initialise arrays with that size if you want

\section{Lecture 6}
	Process Control Blocks
		Things os should know about process
			BIG LIST GOES HERE
				process state turns out to be thread state
				priority used by scheduler
				owner - security considerations
				process generally on one processor (306 core moving cost)
				process group - proceessors working together
				memory and resource considerations
				see if process result can be piped to another process, or that it is waiting for result of this process

	UNIX process parts
		can be scattered as parts somewhere else
		process structure
			some of information of process held here

		user structure
			not instant access to this
			in user space
			some of information of process held here

		In UNIX, text = code

	WIndows NT
		split it up into lots of things in ANOTHER BIG LIST TO COPY YAY

		MISSED SLIDE 3 TO END OF LECTURE
			EMPHASIS ON FORKS

\section{Lecture 7}
	\subsection{Runnable}
		\begin{itemize}
			\item On one core, only one thread/process at the same time. (Exception SMT)
			\item Other processes/threads may be ready to run, or already running
		\end{itemize}
	\subsection{Multitasking}
		Pre-emptive Multitasking
		\begin{itemize}
			\item OS uses some kind of criteria to determine how large of a time slice that task
			\item The more you call yield and switch processes, the more time is wasted and less actual work is done by CPU
			\item \paragraph{Cognitive multitasking}
				
			Threads know that may have thread.yield() called on it and therefore are coded in a way such that when yield() is called, issues are less likely to occur
			
			Advantages
				\begin{itemize}
					\item Control
					\item Predictability
				\end{itemize}
			
			Disadvantages
				\begin{itemize}
					\item Critical Sessions
					\item Efficiency
				\end{itemize}
		\end{itemize}
		Co-operative Multitasking
		\begin{itemize}
			\item Two main ways to approach
			\begin{enumerate}
				\item Process yields right to run
				\item System stop process when system call made
			\end{enumerate}

			\item Doesn't mean task won't run and complete in one go.
			\item Old UNIX (before 2.6) didn't allow pre-emptive calls when making system calls
			\begin{itemize}
				\item pre-emptive multitasking always at user level
				\item hasn't always been preempntive at system level
				\item Actually used to be cooperative in the past
				\item Unix was written simpler in the past, expected it to be simple with blocking calls made.
			\end{itemize}
		\end{itemize}
		

	\subsection{Context Switch}
		\begin{itemize}
			\item Change from one process running to another on same processor, or to handle an interrupt
		\item Has to save the process state before this can occur
		\item Context changes as process executes
		\item Context contains:
		\begin{enumerate}
			\item Registers
			\item Memory (dynamic elements like call stack)
			\item Files \& Resources
			\item Caches
		\end{enumerate}

		\end{itemize}

	\subsection{Returning to Running}
		State Transition
		\begin{itemize}
			\item Store process properties so it can begin again where it left off
			\item Page table to be updated if changing processes
			\item Environment must be restored
			\item If changing threads on same process then may can just restore registers
			\item If system has multiple register sets then could thread change with 1 instruction
		\end{itemize}

	\subsection{OTHER STATES}
		\subsubsection{Waiting}

	Waiting
		To stop unnecessary resource consumption
		Status changed from runnng to waiting

	Suspended
		Different form of waiting

	Java
		Always had Threads from the start
		Threads have generally been user level
		Although Thread.suspend existed that froze thread on system level
			Thread.resume() to restore it
			Issue was some resources are tied to one process, and therefore gets a lock
			Therefore if frozen then other threads can't access it
		Threads.stop() kill thread and force it to release locks that it may have
			But may cause data to be left in inconsistent state

	Waiting in UNIX
		WCHAN can contain numbers, represents address in kernel
		Uses a queue to create a queue for processing
		Queue associated with hash value or kernel addresss

		HERE GOES SOME PROCESS OF HOW IT ALL WORKS

	Finishing
		Resouces used by process need to be accounted for
		Shared resources usage lowers due to process finishing
		Make sure tidying up is done, if not done already
			Don't rely on this, should do this yourself

		"When you log out, you want all your processes to finish too"
			Create a cascading effect, one process shutting down causes other ones associated with it to shut down too

	Reasons to Stop
		Normal Stop
			must call exit routine
			does all required tidyup

		Forced Stop
			Only want some processes to be able to kill specific processes.
				Parents can kill children
				Children can "generally" kill parents since same owner

	UNIX stopping
		Has 'zombie states'
			Process that is finished, until parent checks exit status
		This is a return state/value of a process
		Used so next process/processes can find out how child finishes and continue execution based on this result
		If parent is around and child finishes, child becomes a zombie

		If parent never calls wait
			if parent finishes then zombie is freed

	Another FSM

	Info from Linux Process Table
		NI = nice value
			can be positive a negative
			used to change priorities
				the lower the number, the higher the priority
				negative numbers are super priority
			Only SU can change nice values
			Normal users can only change nice values to positive values
		RSS = resident set size
			memory allocated to it
		TT = teletype
		TIME = how long process has been running for
		CMD = actual command that was executed

\section{Lecture 8}
	\subsection{Scheduling Processes/Threads}
		\begin{itemize}
			\item \textbf{CPU burst time}: time takes for thread running to have to wait for some reason
			\item Basically, the majority of threads stop after processing for not very long time
			\item Therefore if we stop them frequently it doesn't make too much of a difference as they are probably waiting anyway

		\end{itemize}
	
	\subsection{Levels of Scheduling}
		Batch Systems
		\begin{enumerate}
			\item Very long term scheduler
			\begin{itemize}
				\item outside OS, more admin level
				\item STUFF
			\end{itemize}

			\item Long term scheduler
			\begin{itemize}
				\item Have multiple queues
				\item STUFF
			\end{itemize}

			\item medium term scheduler
			\begin{itemize}
				\item Still programmer dependent how its done
				\item STUFF
			\end{itemize}

			\item short term scheduler
			\begin{itemize}
				\item Will mainly look at this one
			\end{itemize}

			\item Dispatcher
			\begin{itemize}
				\item Does the switching from thread/process to another
			\end{itemize}
		\end{enumerate}
			

	\subsection{Scheduling Algorithms}
		\subsubsection{FCFS - First Come First Served}
		\begin{itemize}
			\item No wasting time by determining how to allocate
			\item Use average waiting time and the CPU burst times for processes
			\item Produces Gantt chart looking thing
			\item Weight times are when the processes start
		\end{itemize}

		\subsubsection{Round Robin}
		\begin{itemize}
			\item Pre-emptive version of FCFS
			\begin{itemize}
				\item Still don't let them run to completetion
				\item Use of pre-empting them and time slices
			\end{itemize}
			\item Hard to determine what size time slices to allocate
			\item Some processes are CPU intensive and require longer time slice
			\begin{itemize}
				\item But if let these processes do its thing, user may feel slowdown. 
				\item Interactive processes affected by this
			\end{itemize}
			\item If short time slice then good in terms of interaction as its jumps around to lots of processes.
			\begin{itemize}
				\item However, CPU intensive tasks take longer to complete
			\end{itemize}
			\item Still doesn't have concept of priority

			\item If task takes shorter time than time slice, instantly schedule another task as to not waste CPU cycles.
			\item Average wait time reduced due to forced time slices
			\item Making time slices smaller reduces the average wait time
		\end{itemize}

		\subsubsection{Minimising Average Wait Time}
			\begin{itemize}
				\item Need to know how long CPU bursts are
			\end{itemize}

			\paragraph{Shortest Job First}
			\begin{itemize}
				\item Gets minimum average waiting time
				\item But don't always know all CPU burst times
				\item Therefore use an estimation algorithm. Basing it off previous CPU bursts to estimate how long subsequent bursts will approximately be.
			\end{itemize}

			Pre-emnptive SJF
			\begin{itemize}
				\item Uses arrival time and burst time
				\item Short it not because of CLK interrupt, but because another processor came in with a shorter CPU burst time.
				\item Use remaining CPU burst time remaining if trying to determine if you are going to stop and schedule another process
				\begin{itemize}
					\item If a process has CPUburst = 7 
					\item Something with CPUburst=4 comes at time=2
					\item Compare 5 (7-2) with incoming CPUburst=4
					\item Therefore will stop original processor and run new one since 5 $>$ 4q
				\end{itemize}
				\item If has 2 options with same weight, then up to programmer to choose. Theoretically similar, but in reality will have some weighting choosing one over the other
			\end{itemize}

	\subsection{Handling Priorities}
		Explicit Priorities
		\begin{itemize}
			\item If have very low priority, then there is chance that some priorities will never actually run \textbf{Starvation}
			\item SOMETHING GOES HERE
		\end{itemize}

		Variable Priorities
		\begin{itemize}
			\item Processes get higher priorities the longer they've existsed (aging)
			\item Solves the starvation problem
		\end{itemize}

	\subsection{Multiple Queues}
		\begin{itemize}
			\item Multiple queues exist for things that require different time slices and CPU cycles
			\item Kind of a heirarchy of these processors
			\item Still assumes single processor
		\end{itemize}
		

	\subsection{UNIX processor Scheduling}
		\begin{itemize}
			\item Every process has priority associated with it
			\item Priorities are recalculated every second
			\item Larger number means worse priority. Lower numbers go first
			\item Can \textbf{Nice} a process, adds priority for process (nicer to everybody else)
			\begin{itemize}
				\item Ordinary users can only nice their own processes, thereby delaying their processing
			\end{itemize}
			\item Aging exists, priorities get worse the longer they run
			\begin{itemize}
				\item Worst level exists, so this doesn't continue forever
				\item For every process at worst level, are scheduled in round robin
			\end{itemize}
			\item The longer a process spends waiting, the lower its priority level becomes and therefore higher chance of being executed
		\end{itemize}
		

	\subsection{Old Linux Process Scheduling}
		\begin{itemize}
			\item Used two process scheduling algorithms
			\begin{enumerate}
				\item Time sharing algorithm for most processes
				\item Realtime algorithm for absolute priorities hold over fairness
			\end{enumerate}
			\item Processes have different scheduling classes that determine which algorithm to apply
			\item Uses \textbf{prioritised credit based algorithm} for time sharing
			\begin{itemize}
				\item Process with most credits go first
				\item If process running on clock tick, it loses a credit
				\item If process hits 0 credits then another process chosen
				\item Therefore the more you wait the more credits you get
			\end{itemize}
		\end{itemize}

	\subsection{Linux Real-time Scheduling}
		\begin{itemize}
			\item Linux uses both \textbf{FIFO})First in first out) and \textbf{Round-Robin} scheduling.
			\item In both situations, processes have priority + scheduling class
			\item Scheduler does process with most priority
			\begin{itemize}
				\item If equal priority then choose one that has been waiting the longest
				\item FIFO processes run until exit or blocked, no pre-empting

			\end{itemize}
			\item In Round-robin, processes pre-empted after a while and moved to end of queue.
			\begin{itemize}
				\item Allows
			\end{itemize}
		\end{itemize}


	New Linux Processing


\section{Lecture 9}
	MISSED SLIDE 1 \& 2

	Periodic process
	\begin{itemize}
		\item common that period and deadline are the same
		\item Deadlines and period may change depending on the workload of the system
	\end{itemize}

	Sporadic Processes
	aperiodic process
		things can happen at the same
		if $\infty$ evens can occur at the same time then need to figure out how to allocate it

	Cycling Executives
	Handle periodic processes
	Prescheduled - know information before power machine, so can schedule
	Can't pre-empt because schedule already generated
	Hard to maintain

	CE Schedule
	MAJOR SCHEDULE
	MINOR CYCLE

	\subsection{Scheduling with Priorities}
	Lets you do important tasks first
	CATCH UP

	\subsection{Priority Allocation}
		Fixed
		\begin{itemize}
			\item \textbf{Rate monotomics RM,} shorter period means higher priority
			\item Least compute time LCT, similar to Shortest Job First
		\end{itemize}

		Dynamic
		\begin{itemize}
			\item CPU burst times used/useful
			\item \textbf{Shortest completion time}
			\begin{itemize}
				\item Simnilar to SJF
				\item Uses pre-emption, but requires good information about execution time requirement.
				\item Schedule, and compare the time required to finish computation of process at every cycle
			\end{itemize}
			\item \textbf{Earliest Deadline}, process with closest deadline goes first
			\begin{itemize}
				\item Does this every cycle, and compares all processes that want to be sceduled and their respective deadlines
				\item Add don't cares/idle times for when process is complete before deadline. Counts as $\infty$, allowing another process to run
			\end{itemize}
			\item \textbf{Least Slack Time} (deadline - compute time) gets highest priority
			\begin{itemize}
				\item If no slack time left, then must schedule now.
				\item Slack time doesn't change if it gets process. Due to fact that its deadline gets closer, but its computation has gone for another cycle, cancelling each other out.
			\end{itemize}
		\end{itemize}

	\subsection{Theory} 
		\begin{itemize}
			\item Static priorities, RM is optimal policy
			\item Dynamic priorities, EDF(Earliest Deadline) and LST(Least Slack) are optimal
			\item Only really works for single processors.
			\begin{itemize}
				\item Required more sophisticated processes, to allocate multiple processors
			\end{itemize}
		\end{itemize}

\section{Lecture 10}
	\subsection{Prolbem of Concurrency}
	\begin{itemize}
		\item Sharing resources is a problem
		\item Multiple threads/processes trying to access it at the same time
		\item Some resouces can only be safely accessed by a single thread at a time
		\begin{itemize}
			\item Reading from resources that are being written to.
			\item Writing to a file simultaneously
		\end{itemize}
		\item \textbf{Race Condition}: Where order of thread execution produces different results
	\end{itemize}

		\subsubsection{Example of contention}
		\begin{itemize}
			\item Don't have control over thread execution once threads have started executing
			\item have to \texttt{-lpthread} on linux when compiling C programs to use thread library
			\item \texttt{counter++} seems innocent, but actually has a window for error.
			\begin{itemize}
				\item Due to concurrency, there is contention if multiple threads are the one that calls the function that causes a reaturn
				\item Did not count to 10 a lot of the time due to contention happening a lot of times
			\end{itemize}
		\end{itemize}

	\subsection{Critical Sections}
		\begin{itemize}
			\item \textbf{Mutual Exclusion:} Area of code that it expects only 1 thread active at given time
			\item Need to lock thread when critical session going on
			\item Need to have a way to make sure threads aren't waiting forever (Starvation)
			\item Starvation can be caused by deadlocks of indefinite postponement
		\end{itemize}
		
	\subsection{Software Solutions}
		\begin{itemize}
			\item Both can get lock at same time if multithreaded
			\item Thing dying prematurely
			\begin{itemize}
				\item OS needs to keep track of when things are alive/dead
				\item Always an issue and should have something in place to deal with it, if it were to happen		
			\end{itemize}
			\item Polling	puts unnecessary strain on system
			\item \textbf{Spin lock} - something waitng just doing nothing. 
			\item \textbf{Busy wait} - Waiting when processor doing something, which is something you don't want to happen
			\item Suspended thread after seeing that thread is unlocked may lock it at another time, in which another process has already got a lock \\	
			\item Main problem is multiple threads that sees that \texttt{locked = false}, and trying to set it to \texttt{true}. Due to small vulnerable time gap
		\end{itemize}
		

		\subsubsection{Peterson's Solution}
			\begin{itemize}
				\item \texttt{flag = [false, false]} is a shared variable
				\item Getting lock
				\begin{itemize}
					\item Set your own flag[self] to true, and set turn to another thread, and wait until they either they let you or finish doing process on object
					\item Setting flag = true means that you want to access it. 
				\end{itemize}

				\item Wait when its other thread's turn and they wanna use the file.
				\item Not feasable in real life due to instruction re-ordering

				\item Instruction Re-ordering
				\begin{itemize}
					\item Both compilers and processors do some optimisation at runtime/compile time. 
					\item Users don't have control over this
				\end{itemize}
			\end{itemize}

	\subsubsection{Bakery Algorithm}
		\begin{itemize}
			\item Each thread given number indicating when it can request a lock.
			\item Numbers aren't unique so need to use another form of identifier to distinguish different processors with the same allocated number
		\end{itemize}
			
	\subsubsection{Interrupt Priority Level}
		\begin{itemize}
			\item Can be done by increasing interrupt priority level so other processes can't pre-empt
			\item Before you do a check on a lock, turn interrupt off so you can't be pre-empted.
			\item Only turn off interrupt for certain sections of code so that pre-empting will not be possible for that part only and not block other processes.\\

			\item Disadvantages:
			\begin{itemize}
				\item Doesn't work efficiently with multiple processors present
				\item A message must be sent to all other processors to let them know of the level change. May cause processors to wait
				\item Not all processors at priority level need to be stopped so waste of resources
			\end{itemize}
		\end{itemize}
			

	\subsection{Using Hardware - Test and Set}
		Atomic, create instruction that cannot be divided and must run to completion
		So the locks that it obtains are guaranteed to not be interrupted.
		Testing the value, and setting it in one indivisible instruction.

		\texttt{while test\_and\_set(locked)}
		\begin{itemize}
			\item This removes the gap that is prone to be pre-empted.

		\end{itemize}

		This doesn't solve the issue of a busy wait, nor does it make it fair.

	Getting out of spin
		DIDN"T LISTEN YAY

	Priority Inversion
		If low priority process has lock, as long as it can complete and pass the resource on
		Just need to make sure that the lower priority process can do its task. But sometimes can't due to interrupts and waiting and stuff
		Don't want lower priority to be stuck in ready state, while it still hasn't been scheduled.

		Possible solution
		temporarily increase priority of something with low priority to higher priority only while it uses the resource.
		MORE THINGS

	Placing in a queue
		Once new process realises that resource is in use, it suspends, and reschedules itself.

		Putting process to sleep then the lock may be set to false so process waiting forever

		Put another lock around the code to make sure that locking and unlocking can be done without interrupts

		Busy waits solves this issue. OS puts busy waits on lots of little bits of code, but problem with busy waits is it may be waiting for a while.

	Semaphores
		Solution to concurrency problem
		Basically counter with atomic operations
		2 functions, V(S), and P(S).
		Original value, set to let n number of things NOT SURE AE

		P() is kind of a lock
			If process sees S 0 or less then will wait
		V() is called when finish
			May set S > 0 which may let another process use the resource

	Implementing Semaphores

	UP TO PRODUCER CONSUMER PROBLEM
	(14)
		Want consumer to block so that the buffer will have a value stored in it



\section{Lecture 11}
	Reader/Writer problem
		Readers aren't a problem, as they don't change values
		As you add writers, then it makes it potentially inconsistent

		Only 1 writer at at time in critical section, once it is gone then you can let readers go do their own thing.
		If we have multiple readers, we want them all in there at once with no writers

		Writer prefered
			writer before reader
			prioritises reading of updated values
			read most recent data

			Priority problem again, if writers keep coming then readers will wait forever

		Reader Prefered
			Opposite problem to other one, writers may wait forever

		both of these may end up indefinite postponemenet

		No preference
			Use queue, neithe writer or reader has no priority

	Getting program correct
		(2) had exclusive access semaphore, set to 1 so that only one thing can access it.

		If producer goes twice then overwrites the value in the buffer of original, so no 1:1 mapping of producers to consumers

		If consumers gets there before producer then the \texttt{number\_deposited} is set to 0, producer sees this too and then waits forver and enters a deadlock

	Bad Programmers

		Have to make sure that if you have a lock in a section of your code, to put something in to unlock it too.
			
		Can use things in OS to help programmers

		Can possibly just call unlock if you see another process has a lock on an object and then be allowed to access it. Throws away any safety created if programmer has malicious intents

	Monitors
		Object that allows at most one thread executing inside of it.
		Similar to old school kernel allowing one process to run in it

		As long as you're running in the monitor then you don't have to worry about concurrency issues as the monitor only allows one thing to run at a time.

		Slower due to monitor only doing one thing at a time, and therefore potentially getting a big backlog of tasks to do

	Conditiion variables
		Queue you put thread on when it gets to front
		Uses the \texttt{wait} and \texttt{signal} again to only wake threads when needed

		If you call wait, you always to go sleep.
			If consumer sees nothing in buffer then will call wait and sleep itself and wait for producer to be done

		If you call signal and thing has changed keep going
		Otherwise then you do nothing. Used for situation where producers go after another to make sure buffer values are not overwritten.

	Which thread runs?
		If you allow thread to call signal, to wake up another thread then be careful to make sure thta you don't interfere with its operation.

	Java monitors
		Every object has a lock. This is to allow \texttt{synchronized} methods to work
		If you call a \texttt{synchronized} method then you're asking monitor associated with object if you can go in and do somehting.
		Has inherent \texttt{wait()} and \texttt{signal()} for each object.

		What happens when there is a recursive call to \texttt{lock()}
			Throw error if encounters lock by \texttt{self}
			If continue then need to count how many times locked and unlocked. Make sure that you unlock it as many times as you locked it.

		\texttt{pthreads} Can specify if you want a recursive lock or traditional lock. Tranditional lock will not allow same process to lock something twice.

		They are different
			One condition variable for \texttt{signal \& wiat}
			Not real monitors

\section{Lecture 12}
	Dining Philosophers
		DESCRIPTION

	First solution
		Does wait() on both left and right
		Eat
		Put them back

		They all grab fork on the right and then can't get one on the left. Then die.
		REST OF THIS

	Second Solution
		Basically the people either have both forks, or no forks
		Uses simultaneous wait and signal for getting and returning forks
		No deadlock but doesn't solve starvation problem

		REST OF THIS

		Simultaneous wait
			Uses a \texttt{try-lock}
			Pick up one and see if can grab other too, if can't then put one you have picked up back.


		Problem with this is it is really slow. The constant contention makes it run a lot slower than first solution, even though that one ran into deadlock
		It is possible that one single person never eats. 
		A given person can only eat if both its neighbours aren't eating.

	Just to be safe
		1
			THIS

		2
			THIS


	Equivalence
		If have semaphore then can impelement monitor, and vice versa

		Implementing semaphore with monitor is easy
		Other way around is harder due to lack of conditional.
			Associate semaphore with condition variables.

	Lock free algorithms
		Locks aren't the only way to protect resource/datastructure
		Libraries exist for this for most languages

	Lock free modification
		uses \texttt{cas()} Compare and swap
		Basically check if value checked has changed. If not then replace with new value.
		Keep checking until the value
		
	Deadlock
		When 2 processes want something that the other has and vice versa. (Classic deadlock)
		Anything waiting for a resource that the 2 processes fighting for also indirectly joins the deadlock.

		Conditions
		\begin{enumerate}
			\item 	Circular linked list
			\item Resources can't be shared
			\item Only owner can release resource
			\item Process holding resource while requesting another. \textbf{Often forgotten}
		\end{enumerate}
			
		Detection
			Use graph and find cycles
			Allocation are node, request are edge

		Results
			Deadlock has to be resolved somehow
				Killing process. Bad since you don't know current state of process.
				Can use priority or age to select process to delete.
			May enter back into deadlock instantly.
				Can remove all processes. Overkill but solves problem.
			Can rollback or restart. But make sure that same process not deleted/rolledback constantly


			Killng stuff not generally good idea due to potentially inconsistent state.

		Prevention
			Ordering of resources
				Make circular list of processes, so you can only get resources in a predetermined order. Prevents the basic deadlock situation.

				If A->B->C.
				If have A can get B
				If have B, have to release, get A then get B

			Resources not sharable.

			Only owner can release resource

			Process can hold resource while requesting another
				One resource at a time
				Return before requesting
				Allocate all resources at same time.

		Avoidance
			More of a runtime thing. Very conservative stratergy
			Check requests' safety, before allowing it to go ahead.
			Might end up have resource free while something waits for it due it it possibly making deadlock later.

			Occur when both processes have resources and both require one more from depleted resource pool.

		Banker Algorithm
			If given request, then assume permisison granted.
			Go through processes, and see what processes it wants not and in the future, compare with the list of available resources.
			Then actually grant it access if it meets this. Otherwise do nothing.

			Check if the processes can finish with given resources left if trying to allocate to another. 
			Need to ensure that all processes can definitely finish.
			"Deadlock may occur" not allowed. Only "deadlock can't occur" allowed

\section{Lecture 13}
	Distributed Deadlock
		Instead of worrying about order that you get resources, instead order processes that are executed by their priorities. 
		Lower levels are rolled back and higher ones go earlier

		Detection
			A -> B	means that A is waiting on something B holds
			Sometimes that you can only see deadlock when you combine multiple graphs.
			Can have something ask all sites for their waitFor graphs (to try find global deadlocks)

			Centralised deadlock detection
				Timing is an issue and may lead to false positives.
				Graph only approximation of real resource allocation.
				Can use timestamps to avoid false deadlock

			Distributed approach
				Extra node ($P_{ex}$) in each local waitfor graph
				Local processes waiting on external stuff goes to this $P_{ex}$
				If cycle with $P_{ex}$ in it exist, \textbf{could} have a deadlock. Each local site can check this.
					Then goes and ask other sites
					Deadlock handled if found
					Otherwise continue as normal

	Time stamp prevention
		wait-die
			If resource held by older process, younger process can't wait, and dies. Since it hasn't done as much work, and tries again.

			If resource held by younger process, older process allowed to wait.

			Keep age for when you first try get a resource

		wound-wait
			Younger process allowed to wait for older process.
			Other away around. Older process doesn't wait for younger process. Kills it and takes resource.

	Messages
		Can be used to control concurrency
		Sending information to another process can be done by
		\begin{enumerate}
			\item Shared resource
			\item Message passing
			\begin{itemize}
				\item Address message
				\item Transport message
				\item Notify receipeint
				ANOTHER ONE
				\item \texttt{send(destination, message)}
				\item \texttt{receive(source, message)}
				\item \texttt{write(message)}
				\item \texttt{read(message)}
			\end{itemize}
		\end{enumerate}

		Design decisions
			Either have sender block or not
			If writing to a file, want to send information as soon as possible.

			Receiver should be blocking, you don't want any interruptions.
			Receiver can choose a bunch of message types to stick around for and receive if any come.

			If sender doesn't block then need somewhere to store the messages until the receiver retrieves the message.

		Storaging messages
			\begin{enumerate}
				\item Have sender send message striahg to other process
				\item Or have the page saved, and pointer sent so receiver knows where it is
				\begin{itemize}
					\item Need to not overwrite information until it hsa been read
					\item Should also make this address read only for recepient so it can't be tampered with
				\end{itemize}
			\end{enumerate}

			COMMUNICATION PROCESS TO PROCESS (12)

			Indirect Communication
				Mailbox and ports
					Mailbox ownership
					\begin{enumerate}
						\item Owned by system
						\begin{itemize}
							\item Persist without process (if finish)
						\end{itemize}
						\item Owned by process
						\begin{itemize}
							\item Creator pass ability to receive
							\item mailbox gone if process finish
						\end{itemize}
					\end{enumerate}

	UNIX pipes
		General
			Something that contains data
			Buffering mechanism
			Pipe fills designated array with file descriptors (address on open file table) which basically makes it look like it is variable that contains the file/s
			Can use typical \texttt{read} and \texttt{write} calls
			\texttt{ls -al | grep Doc | wc -l} \tab Vertical bar is pipe

			\begin{enumerate}
				\item Create new process using fork
				Call exec on ls
				Forks to grep
				\begin{itemize}
					\item ls end is writing, grep end is reading
				\end{itemize}
			\end{enumerate}

			UNIX does this piping by redirecting \texttt{stdin} and \texttt{stdout}

		Full Pipes
			If full (due to specified pipe size), and tries to send more information through the pipe. Will block when buffer fills up to not lose any information

		Broken Pipe
			If trying to read from pipe with no sender, get EOF. Otherwise it may wait forever.
			If reader has died, sender has no point to keep send information; send signal to the process letting it know that nobody is listening to it.

			Pipes aren't simply single sender and single reader.
			Chunk sizes at least 512bytes. Then if message is equal or smaller than it, it will keep it as a whole.

		Mach ports
			Underneath OSX
			Ports that write/read to/from.
			Only one reader per port
			Process allocated a certain number of ports for communication

		UNIX process communication
			SIGUSR1		user level signal you were sending

\section{Lecture 14}
	\subsection{Sockets}

\section{Lecture 15}

\section{Lecture 16}
	\subsection{Design Decisions}
		need to store variable files and different types
		block is smallest addressable region
			see it as an array of blocks
		sector is smallest area the device could communicate with

	\subsection{File attributes}
		Information about files
		things
		\begin{itemize}
			\item Name 
			\begin{itemize}
				\item may have more than 1 name for a file
				\item length of name
				\item limitations to name (can't use characters) 
			\end{itemize}
			\item Location
			\item Size
			\item Owner
			\begin{itemize}
				\item Protection, and grant access rights
			\end{itemize}
			\item Access Information
			\item Dates/Times (Creation, modification)
			\item File Types
		\end{itemize}
			
	\subsection{File Name Limits}
		\begin{itemize}
			\item NTFS
			\begin{itemize}
				\item extend paths up t 32k length
				\item ordinary path up to 256chars
				\item Win10 can ignore limit
			\end{itemize}

			\item Linux
			\begin{itemize}
				\item Path limit 4k bytes
				\item commonly 255 bytes per path component
			\end{itemize}

			\item APFS
			\begin{itemize}
				\item 255 characters per path component
			\item Don't know maximum length
			\item iOS 10.3 converted this on devices on the fly.
			\end{itemize}
		\end{itemize}

	\subsection{File Type}
		System has to know about it to perform operations

		<<EG SECTION TO COPY>>

		All OS know about executable binary files
		OS specific structure about how to load information from file/s

		\subsubsection*{Dealing with File Types}
			\begin{itemize}
				\item Easy way to do it - just add file type to the end of the name.
				\item Extensions are mapped to registry so it knows how to treat it
				\item Doesn't stop people renaming extension
				\item UNIX uses numbers in front of file data (first few characters/bytes have this information)
				\begin{itemize}
					\item \texttt{ftype M4A} means that it is .m4a type
					\item \texttt{PDF1.3} - PDF format
				\end{itemize}
			\end{itemize}

		\subsubsection*{Old Macintosh Solution}
			Used to be called MFS (Mac File System)
			Wanted to have icons for files
			Stored too much information. stored what program created the file so it can be opened again later.

			2 parts to a file
				resource fork
					<<LIST OF THINGS>>

				data fork
					<<LIST OF THINGS>>

			Done before computers were networked. Things broke due to OS incompatibilities.
			This is incorporated into NTFS, but extended to have as many parts as you want to a file as programmer wanted.

			in OSX, \texttt{bundles} seem like a single file, but is actually a directory.	

		NTFS
			Highly structured way to look at a file.
			File seen as a set of file attributes.
			Only one of the attributes contain the file data.

			File system commonly have a Btree to make finding files more efficient.

		Alternate Data Streams
			Hidden information about files
			Need to use other programs to view it

			Starts with colon. Associates this alternate data stream with current directory.

			Master file table, each file has approximately 1kb allocated to it.

		Representing Files on Disk
			Have to store files in constant sized blocks on disk

			<<LAST 2 BULLETS>>

		Structure
			metadata = <<DEFINITION>>
			single level = <<DEFINITION AND USE>>
				Number of files grow as you put files in, B-tree used sometimes.

			Two level
				users are top level, can only have flat directory
				not used by many OS

			Normal
				tree structure
				files organised by using collections of more files

				Should you be able to write directory that you own
					Don't want to lose some of the metadata that contains what is stored inside directory
					can also lose list of blocks allocated, then you get full access to disk if you modify this

		Sharing Files and Directories
			<<LOTTA TEXT>>

		Hard Links
			<<MORE TEXT>>
			With hard links, both files are treated equal.

			\texttt{ln old\_filename new\_filename}
			Create directory entry with pointer to file inode (hold real information about a file)

			\texttt{mklink /H newfilename oldfilename}
			How to do it in Windows.
			/H to denote that it is to be a hard link.
			Make entry of master file table. But also puts a bunch of information in so you don't have to go to the master file table every single time.

		Soft/Symbolic Links
			The contents of a symlink is the identifier to the real file.
			OS knows to treat it as link due to the \texttt{l} in \texttt{ls -l}
			Length of the file is length of filename that it points to
			Only holds real name of the file. If you rename file, symlink breaks

			Windows shortcuts
				<<THING>>
				Windows should be able to continue tracking even if you do things to the original file.
				Such as moving file to different volume, move to network.
				However this uses lots more resources and does more work to allow this.

			Mac Aliases
				Can make alias from GUI.
				Contains real identifier of the file. 

				However, they moved to UNIXlink at some point and incorporated symlinks.
				But symlinks work differently and are 'dumber'

				Now MacOS stores both ID and filename. Checks the file name first, then ID if file doesn't exist.

\section{Lecture 17}
	\subsection{Cycles}
		Generally don't want cycles in the directory graphs
		Have infinitely many names for all files in the cycle.
		Naive search would fail, since you may get stuck in the loop and never reach file you're searching for.

		One solution would be to just not allow hardlinks, but allow symlinks.
		Can still get infinite loop, but OS thinks its in loop if it reaches a certain number of symlinks.

	\subsection{deletion}
		Have count of how many links to files
		If delete, then reduce the number so other names can still point to data
		If real file deleted then could have dangling pointers

	\subsection{What's in directory entry}
		UNIX
			\begin{itemize}
				\item filename
				\item file attributes (How much more?)
				\item pointer to file attributes
			\end{itemize}

			UNIX stores this attribute information in \textbf{inode} that also contains number of hard links to file.
			UNIX directory is a table of names, and their inode numbers

			inode table replicated so not a single point of failure.

		NTFS
			Master file table contains folder information.

			<<YEP NEED TO TYPE A BIT>>

			Not all information you get may be correct

	\subsection{Terminology}

	\subsection{Finding File Blocks/Metadata}
		data on disk that isn't contents of file
		\subsubsection{Continguous }
			store start block and length of each file.
			Efficient for hard disk as head doesn't have to move very much.
			If have both of these values then can deal with any part of the file.

			Can't do simple things like make file larger. Need to find hole large enough in disk to fit new file size.

			\begin{enumerate}
				\item \textbf{First fit}\\
					Find first hole that will fit
				\item \textbf{Next fit}\\
					Continue searching where you last finished searching
				\item \textbf{Best fit}\\
					Fit as best you can, hole closest in size. Disk ends up with small holes left that you can't fit more files in
				\item \textbf{Worst fit}\\
					Find hole with largest space, lets you fit more files in there later.
				\item \textbf{Buddy algorithm}\\

			\end{enumerate}

			Figuring out how much space to allocate is also difficult thing to do.
			If give too little space then increase in file size annoying
			Otherwise, may be wasting space.

		\subsubsection{Linked Allocation}
			Little bit of block used to point to next block that is part of a file.
			Linked list implementation.

			Simple.
			No more external fragmentation, all blocks can be used.

			Direct or random access is difficult.
			Need to read block to know where next block is.
			If one block fails, can lose rest of file.

			Can cache blocks associated with a given file.

		\subsubsection{MS-DOS \& OS2 FAT}
			File allocation table.
			Part of disk holds this table, is array of numbers that represent blocks.

			If can load whole allocation table to memory, then can do direct access.

			Works best if number of things allocated isn't very large as it is preferable to load whole table into memory.


<<MISSED A LECTURE>>

	slide 12<<Opening a file in UNIX>>

		fd example doesn't use root directory
		changing where stuff redirects to/from by closing an opening file.

<<FILE VERSIONING>>
	
<<19 slide 15>>
	Better Methods
		<<>>
	Transparency
		Things are hidden. Not seeing thed details/implementation
		User shouldn't be able to see differences/complications
		Location Transparency
			No connection between name of file and where it is stored


		Migration Transparency
			Moving file without noticing it moving
			Location Independence - name doesn't change when you move it


	Collections of Files
		 Don't keep all information for all files
		 <<>>

	Using remote files
		Need to transfer file data over network to client
		May cache it to client memory or local disk.
		Can be expensive
		Also need to let all users know if cached, that somebody has modified the file.

	Caching
		Blocks of file cached locally
		Accessing file done to the cache
		Modify file:
			Write through - every write requires user to send black back to server
			Delayed Write - Update sent to server delayed, or when file closed.

		<<PROS CONS>>>

	Consistency Semantics
		way changes in data is distributed

		UNIX - changes immediately visible
		SESSION - process gets copy of file and changes not visible until file is closed.
	
\section{Lecture 20}
	Stateful
		Server knows who has file and what they can access. Keeps track of file pointer too.
		Client gets identifier to use to access the file
		Server can intelligently cache files that it knows client it already trying to access
		State information lost if server shuts down/crashes.
		If client dies, 

	Stateless
		Server doesn't hold anything about state of system
		Need to pass information to and from server constantly.
		A lot easier to restart the server/system.
		If client goes down, not a problem from server POV. Since it only just replies to requests.
			Only if pure stateless. In reality the server will store some kind of information.

	NFS
		Remote service technique, mostly stateless
		Add some information to the inode. Contains a bit to denote if file is local or not.
		No need for dedicated servers
		All machines share files with each other. Every machine can be server
		Can mount things whereever you want (If you're an admin)
		Works in heterogeneous environment. Doesn't matter what machines were using, NFS can work.
		Need to make sure that when you perform operation on server, that adaptations/conversions happen since server and client may not be running in same environment.

	Automounter
		Client mounting/unmounting directories in other systems on demand.
		<<MORE>>

	NFS protocol
		make system call
		virtual file system determine if local or remote
		??
		request goes to vfs on remote machine
		does process locally
		go back to result

	<<PROBLEMS WITH NFS>>

	AFS
		mount point at /afs/...
		tries to cache as much as possible.
		Uses location database to track where things are.
		<<:D>>

		Shared access to files
			Access controllers
			Session semantics - file only updated when file is closed.
			Callbacks
				Promise from server that given file is up to date.
				Once server gets update to file, breaks all callbacks other clients have about the modified file
				Lost update possible if 2 clients update the same file.


\section{Lecture 21}
	SAN and NAS
		NAS <<>>
		SAN <<>>

\section{Lecture 22 - Memory}
	classic memory heirarchy
		primary = ram
		secondary = Disk
		Tertiary = Archival

	Address binding
		Compile Time
			Put instruction at fixed address, call using jump instruction

		Load Time
			Object modules uses tables of offsets
			Mapping done as modules loaded
			Precompiled libraries

		Run time
			Mapping of final address maintained on the go
			Used in conjunction with load and compile times

	Memory spaces
		Need to protect OS memory from programs, and enabling programs larger than memory to run

		Split memory
			Can protect with single fence register. 

	Dividing memory
		2 registers to denote how much memory a job should have access to. If try to get sometin gout of that range then should not work since it is violating your allocated space

	Two different addresses
		Make process feel like it starts at address 0. Uses an offset to get real address.(relocation register)

		This is a big conceptual change, since it now has 2 addresses to represent the same address.

		Everything needs to be in contiguous memory.


	Splitting memory to smaller chunks
		Uses something similar to file allocation table.
		Stores [Chunk, base, limit]

		Two approaches
			Same sized chunks - pages
			Variable sized chunks - segments

			classic argument about varible and static about flexibility and simplicity

	Paged System address translation
		Local address divided into
		\begin{enumerate}
			\item Page number\\
				Index to which page table contains base address
			\item Page offset\\
				Added to base address to get physical address.
		\end{enumerate}

	Frames and Pages

	Tables

	Different sized chunks

	Segments

	Allocation stratergies
		No internal fragmentation, only allocate space we want
		Can get external fragmentation
		Stratergies
		\begin{enumerate}
			\item First fit
			\item Next fit
			\item Best fit
			\item Worst fit
		\end{enumerate}
		Defrag memory if need large chunk, faster than doing it to disk

	How much space in hole
		Knuth's 50\% rule. If N segments then N/2 holes.
		If average hole size same as averages segment size, need to keep 1/3 of memory free


\section{Lecture 23}
	\subsection{Half speed memory}
		\begin{itemize}
			\item If paged or segmented memory, then need 2 memory access to get logical memory address.
			\begin{itemize}
				\item Page/segment table query
				\item Data query
			\end{itemize}

			\item Memory management unit caches recent page table information in faster hardware cache
			Stored in \texttt{Translation look-aside buffer} TLB
		\end{itemize}

	\subsection{Average access time}
		Hit ratio - times pages found to not found in associated registers

	\subsection{TLB coverage}
		Smaller the cache the better
		But generally need larger page sizes or overall cache too small. But more IO therefore internal fragmentation
		Variable page size good, but need good allocation algorithm

	\subsection{Page table size}
		\begin{itemize}
			\item If 32bit address space with 12bit offest, then get about a million entries
			\item Most process don't use all memory
			\item Limit page table values to valid ones
			\item Use page table lengh register, with valid bit flag
			\item Only allocate parts of table that we need
		\end{itemize}

	\subsection{Inverted page tables}
		Page table now only contains [pid, page number]
		Frame is the index of the page table.
		Address based off both pid and page number, hash table can be used for allocation.

	\subsection{Paging and segmentation}

	\subsection{Programs larger than memory}
		Swapping - moving pages in and out of disk

	\subsection{Does it all have to be there?}
		Try provide more memory than RAM
		In x86 there may be less logical memory than physically there.

	\subsection{Locality of reference}
		
		
\section{Lecture 24}
	\subsection{Effective Access Time}
		Since processors now thinks it has fast memory, but stored on disk. It will appear that the process is a lot slower due to having to access that much slower memory.
		
		\subsubsection*{Calculation}
		Accommodate for:
		\begin{itemize}
			\item TLB hit
			\item TLB miss and page table hit
			\item TLB miss and page table miss, requiring getting another page.
		\end{itemize}

	\subsection{How often we want page faults}
		Don't want it to happen very often.
		If want to be half as slow (compared to everyting in RAM) then need to only get page fault 1/600,000 times

	\subsection{Reducing page faults}
		\begin{itemize}
			\item Different processes access different number of pages in memory.
			\item Allocate frames equally or propotionally depending on priority.
			\item Need to have minimum \& maximum number of pages.
			\item Need currently required pages in memory
		\end{itemize}

		
	\subsection{Working sets}
		\begin{itemize}
			\item Used to keep track of pages needed in real memory to keep process running. Observe process over short window and record the page accesses to determine the working set.
			\item Finding this time window is hard since you don't want it too short (not enough information) or too long (too many pages)
			\item Using a \textbf{reference bit} on the pages that are accessed allows identification of these used pages.
		\end{itemize}
		
	\subsection{Page Fault Frequency}
		\begin{itemize}
			\item Used to control number of frames allocated to process
			\item The frequency of page faults drops a lot when you initially increase number of pages. But law of diminishing returns exists, so set upper and lower bounds and add/remove frames to stay within them.
		\end{itemize}
		
	\subsection{Choosing pages to replace}
		\begin{itemize}
			\item Need to replace page if no free ones left
			\item 2 ways to select these pages
				\begin{itemize}
					\item \textbf{Global}: any frame can be chosen. Number of frames for process varies.
					\item \textbf{Local}: frame must be in process' allocated frame set. There are less frames to choose from.
				\end{itemize}
			\item Normally global replacement used.
		\end{itemize}
		
		\textbf{Picking:}
		\begin{itemize}
			\item Unmodified pages don't have to be written to disk. \textbf{Dirty bit} in page table entry used to determine if changes have been made to frame.
			\item Pages that aren't going to be used soon in the future should be replaced, but can't see into the future.
		\end{itemize}
		
	\subsection{Selection algorithms}
		\begin{enumerate}
			\item \textbf{Random}
			\begin{itemize}
				\item Every process treated equally
				\item Easy to implement
				\item With enough pages the chance of worst case very low
			\end{itemize}
			
			\item \textbf{First In First Out (FIFO)}
			\begin{itemize}
				\item Queue of pages, remove at head add to tail
				\item Simple
				\item Important pages replaced as often as less important ones
				\item \textbf{Belady's anomaly }- increasing number of pages can increase page faults.
			\end{itemize}
			
			\item \textbf{Least Recently Used (LRU)}
			\begin{itemize}
				\item Assumption that if page not used recently then won't be used in near future
				\item Generally better than FIFO, but not all the time.
				\item Cannot suffer from Belady's anomaly because recently accessed pages have higher priority and will therefore not be replaced. It does not assume that the first page loaded in is safest to replace.
				\item More expensive as need to find a way to store last access time for each page.
				\item \textbf{Or} can have list of pages and move to top of list if accessed.
				\item \textbf{Approximations:}
				\begin{itemize}
					\item \textbf{Reference bit} Set when page is used. One per tick, a right shift is done to the value with either a high or low passed in depending on if the page was accessed. These values are compared for each page and one with lowest value is replaced.
					\item \textbf{Second chance}: Algorithm based off FIFO, but if referenced bit of first in page is set, it unsets it and moves it to back of queue and checks the next one.
				\end{itemize}
			\end{itemize}
			
			\item \textbf{Least Frequently Used (LFU)}
			\begin{itemize}
				\item Uses count of memory accesses per page
				\item When page needs replacing, does it on page with lowest number
				\item Pages can stay longer than needed if accessed many times in short period of time.
				\item Not commonly used
			\end{itemize}
			
			\item \textbf{Most Frequently Used (MFU)}
			\begin{itemize}
				\item Reverse of LFU
				\item Concept behind this is that pages with few accesses are newly added and may need to be used later
				\item Not commonly used
			\end{itemize}
		\end{enumerate}

	\subsection{Windows VMM}
		\begin{itemize}
			\item \textbf{Virtual Memory Manager} runs in backgorund maintaining memory policies.
			
			\item Processes use working set min/max
			\begin{itemize}
				\item Process guaranteed working set min
				\item If number of frames below max then try to allocate more
				\item If not enough frames then trimmed to min
				\item Default size = \texttt{30}
			\end{itemize}
			
			\item Privileged processes lock pages in real memory, for things like real-time processes and device drivers
			
			\item \textbf{Clustering} - pages surrounding also get brought in. Assume that if you pull in a page then you may need to use ones around it too to reduce page replacement time.
			
			\item Windows prefetching
			\begin{itemize}
				\item pages and files references in 10 seconds of opening application
				\item Keep track of this information, loaded up again next time app opened.
				\item Defrag every couple of days.
			\end{itemize}
		\end{itemize}
		
	\subsection{Thrashing}
		\begin{itemize}
			\item When number of pages in all working sets higher than number of available pages.
			\item Everything will be a page fault, severely affecting work efficiency.
			\item \textbf{Batch system} can thrash if set up to increase number of programs at a time. But low CPU utilisation will lead to thrashing.
		\end{itemize}
		
	\subsection{Location of process memory}
		Addressable memory in UNIX/Windows scattered in many places and page files not loaded yet or paged out.
		
\section{Lecture 25}
	\subsection{Protection}
		\begin{itemize}
			\item \textbf{Protection} mechanism of controlling access to resources
			\item \textbf{Subjects} active components in system that use resources
			\item \textbf{Objects} resources being used
		\end{itemize}
		
		Objects can be subjects. Want to ensure that subjects only access the objects they are permitted to.
		
	\subsection{Goals}
		Protect against: Malicious intent, Stupidity, Accident, Errors\\
		
		Want to both make sure that subjects only access objects they are permitted to, but also to limit access to the \textbf{minimum} required to achieve their goals. (\textbf{need to know principle})\\
		
		Access to objects should be mediated by a \textbf{reference monitor}
		
		\subsubsection{Examples}
			\begin{itemize}
				\item \textbf{Privileged Instructions} - process must be executing in kernel mode with execute without exception
				\item \textbf{Memory Protection} - kernel address space protected from user level instructions. Other process addresses are also protected
				\item \textbf{File System} - User files are protected from another user
			\end{itemize}
			
	\subsection{Protection domains}
		\begin{itemize}
			\item Access right associated with protection domain
			\item Processes execute inside protection domain and has its rights \& privileges.
			\item Normal system can't keep up with all subject/object/access rights. Therefore combined and stored in pairs of: \tab $<object, rights>$
		\end{itemize}
		
	\subsection{Intersection of domains}
		\begin{itemize}
			\item Domains can overlap
			\item Therefore permission can be shared
			\item Need way to switch between domains, start domain has to be able to switch to resulting one.
		\end{itemize}
		
	\subsection{Crossing domains}	
		\begin{itemize}
			\item Doing so is dangerous
			\item Commonly used to attack systems
			\item Want users to have controlled access to resources.
			\begin{itemize}
				\item user domain allow access to program
				\item program domain allow access to resources
			\end{itemize}
		\end{itemize}
		
		\textbf{UNIX}
		\begin{itemize}
			\item Domain associated with user and group
			\item Running program take on permission of user
			\item Can choose to make program run in user or group mode.
		\end{itemize}
		
	\subsection{How to \texttt{setuid}}
		\begin{itemize}
			\item 	\texttt{chmod u+s} on something. When program is run, runs as it if was executed by user.
			\item 	If you can create another process when in a setuid program, then will be assumed that uid had executed/created it.
			\item 	Very dangerous, if \texttt{superuser} then will have full permissions
		\end{itemize}
		
		\subsubsection{Precautions}
			\begin{itemize}
				\item Restrict UID. Don't use \texttt{root}
				\item Reset UID when calling \texttt{exec}
				\item Close unnecessary files before calling \texttt{exec}. If priviledged file open then will still be able to access it.
				\item If need to use \texttt{root} then do it in restricted root directory. (using \texttt{chroot} command)
				\item Invoke subprogram using fully fledged name
			\end{itemize}
			
	\subsection{Multics}
		\paragraph{Ring structure} If ring more outer than another then has more privileges.\\
		
		\textbf{Segments}:
		\begin{itemize}
			\item Each file loaded as segment. Has associated permissions and ring number
			\item Access to other segment depend on: [current ring number, target ring number, type of access required]
			\item Sometimes lower ring number needs to do something in higher permission ring. Only specific entry points allow this.
		\end{itemize}
		
		\textbf{Other approaches:}
		\begin{itemize}
			\item \textbf{Special Directories} with programs running in privileges of directory. \\Safer than \texttt{setuid}
			\item Have server be the ones that execute privileged instructions
			\item Ensure return of domain after system call
		\end{itemize}
		\textbf{NOTE}: Be careful when doing all of these
		
	\subsection{Access Matrix}
		\begin{itemize}
			\item \textbf{rows} represent domain
			\item \textbf{columns} represent objects
		\end{itemize}
		
		\texttt{access(i,j)} is set of operations that process in domain (i) can invoke on object (j)
		
		\subsubsection{Changing permissions}
			\begin{itemize}
				\item When new object, new column added and permisisons set.
				\item Domains objects too, therefore switching domain is only allowed when you can execute the object
				\item 
				\item When something has a star (\texttt{read*}) then can copy permission on the same object/column. 
				\item If something has \textbf{owner} then can do whatever they want to that column.
			\end{itemize}
			
	
\section{Lecture 26}
	
	
	
	
	
	
	
\section{Lecture 31}
	


\end{document}
